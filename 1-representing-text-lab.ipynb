{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Representing Text Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lesson, we'll get started with the torchtext library, and practice downloading data, tokenizing the data, and numericalizing our data.  Let's get started."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading our Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, get started by loading the `datasets` and `data` modules from `torchtext`.  Also import the `torch` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next let's define our Field and LabelField objects.  We should set up the text field so that we use the spacy tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = None\n",
    "LABEL = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use the `TREC` dataset from the `datasets` module.  Specify `fine_grained = False`, so that we only have 6 categories instead of 50.  Assign both the train and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data, test_data = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, let's get started by looking at how long the training data is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5452"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)\n",
    "\n",
    "# 5452"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we call the `fields` method, we can see a dictionary that points to the fields we defined earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': <torchtext.data.field.Field at 0x1612a9a10>,\n",
       " 'label': <torchtext.data.field.LabelField at 0x1717f9a10>}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# {'text': <torchtext.data.field.Field at 0x1333d4a90>,\n",
    "#  'label': <torchtext.data.field.LabelField at 0x132a27d90>}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, let's select our first example, to see what kind of data we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torchtext.data.example.Example at 0x164d54e90>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_example = None\n",
    "\n",
    "first_example\n",
    "\n",
    "# <torchtext.data.example.Example at .... > "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the text of the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['How',\n",
       " 'did',\n",
       " 'serfdom',\n",
       " 'develop',\n",
       " 'in',\n",
       " 'and',\n",
       " 'then',\n",
       " 'leave',\n",
       " 'Russia',\n",
       " '?']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# ['How',\n",
    "#  'did',\n",
    "#  'serfdom',\n",
    "#  'develop',\n",
    "#  'in',\n",
    "#  'and',\n",
    "#  'then',\n",
    "#  'leave',\n",
    "#  'Russia',\n",
    "#  '?']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer the question below.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# essay form please\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I joke."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, next we want to numericalize our text and our labels.  Let's first build the vocabulary for our text.  Here, we do not need to set a `max_size` as we have a fairly small dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build vocab for text data here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also build the vocab for the LABEL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(None,\n",
       "            {'ENTY': 0, 'HUM': 1, 'DESC': 2, 'NUM': 3, 'LOC': 4, 'ABBR': 5})"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LABEL.vocab.stoi\n",
    "\n",
    "# defaultdict(None,\n",
    "#             {'ENTY': 0, 'HUM': 1, 'DESC': 2, 'NUM': 3, 'LOC': 4, 'ABBR': 5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the 10 most frequent words in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('?', 5352),\n",
       " ('the', 3614),\n",
       " ('What', 3246),\n",
       " ('is', 1679),\n",
       " ('of', 1547),\n",
       " ('in', 1138),\n",
       " ('a', 1014),\n",
       " ('`', 835),\n",
       " ('How', 764),\n",
       " (\"'s\", 721)]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# [('?', 5352),\n",
    "#  ('the', 3614),\n",
    "#  ('What', 3246),\n",
    "#  ('is', 1679),\n",
    "#  ('of', 1547),\n",
    "#  ('in', 1138),\n",
    "#  ('a', 1014),\n",
    "#  ('`', 835),\n",
    "#  ('How', 764),\n",
    "#  (\"'s\", 721)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, seems like a text related to questions.  Next, let's use the BucketIterator to batch our data.  Let's set a batch size of 50.  And let's batch both our training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batches, test_batches = None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_batches)\n",
    "# 110"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 110 batches makes sense as we have roughly 5000 training observations.  Ok, now we can explore what this returns if we iterate through `train_batches` and then break from iterating after the first iteration.  If done correctly, `first_text_batch` should be assigned to the first batch of documents, and `first_label_batch` should have the corresponding labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select first_text_batch, first_label_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([25, 50])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_text_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_label_batch.shape\n",
    "\n",
    "# torch.Size([50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the first observation in the batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   4,   23, 8153, 7851,   43,    2,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_observation = None\n",
    "\n",
    "first_observation\n",
    "\n",
    "# tensor([   4,   23, 8153, 7851,   43,    2,    1,    1,    1,    1,    1,    1,\n",
    "#            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
    "#            1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a method to take in a vector and translate it to a list of words using the vocab object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec_to_words(vector):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What',\n",
       " 'do',\n",
       " 'peacocks',\n",
       " 'mate',\n",
       " 'with',\n",
       " '?',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>']"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_to_words(first_observation)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lesson, we practiced using the `torchtext` library.  We saw how we can both download and tokenize our data, then numericalize by building the vocabulary and using the bucketiterator, and finally, how to convert our numericalized documents back to text."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
